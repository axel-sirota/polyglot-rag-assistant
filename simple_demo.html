<!DOCTYPE html>
<html>
<head>
    <title>Voice Demo - MVP</title>
    <style>
        body { font-family: Arial; max-width: 600px; margin: 50px auto; padding: 20px; }
        button { padding: 15px 30px; font-size: 18px; margin: 10px; cursor: pointer; }
        #status { margin: 20px 0; font-size: 18px; }
        #response { margin: 20px 0; padding: 20px; background: #f0f0f0; min-height: 100px; }
        .recording { background: #ff4444; color: white; }
    </style>
</head>
<body>
    <h1>ðŸŽ¤ Voice Assistant Demo</h1>
    
    <button id="recordBtn">Start Recording</button>
    
    <div id="status">Ready to record</div>
    
    <div id="response">Response will appear here...</div>
    
    <audio id="audioPlayer" controls style="width: 100%; margin-top: 20px;"></audio>
    
    <script>
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        const response = document.getElementById('response');
        const audioPlayer = document.getElementById('audioPlayer');
        
        let mediaRecorder;
        let audioChunks = [];
        
        recordBtn.onclick = async () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                // Stop recording
                mediaRecorder.stop();
                recordBtn.textContent = 'Start Recording';
                recordBtn.classList.remove('recording');
                status.textContent = 'Processing...';
            } else {
                // Start recording
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };
                    
                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        
                        // For demo, simulate API call
                        status.textContent = 'Transcribing...';
                        await new Promise(resolve => setTimeout(resolve, 1000));
                        
                        // Simulated response
                        const transcript = "Find flights from New York to Paris";
                        response.innerHTML = `
                            <strong>You said:</strong> ${transcript}<br><br>
                            <strong>Assistant:</strong> I found several flights from New York (JFK) to Paris (CDG):<br>
                            - United UA914: $450, departing 10:30 AM<br>
                            - Air France AF007: $520, departing 6:30 PM<br>
                            - Delta DL264: $480, departing 11:45 PM
                        `;
                        
                        // Simulate audio response
                        status.textContent = 'Generating audio response...';
                        await new Promise(resolve => setTimeout(resolve, 1000));
                        
                        // For demo, use a placeholder
                        audioPlayer.src = URL.createObjectURL(audioBlob);
                        status.textContent = 'Done! (In production, would play AI response)';
                    };
                    
                    mediaRecorder.start();
                    recordBtn.textContent = 'Stop Recording';
                    recordBtn.classList.add('recording');
                    status.textContent = 'Recording... Speak now!';
                    
                } catch (err) {
                    status.textContent = 'Error: ' + err.message;
                }
            }
        };
    </script>
</body>
</html>